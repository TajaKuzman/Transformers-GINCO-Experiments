{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"3-recreating-peters-final-code.ipynb","provenance":[],"collapsed_sections":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"2ba9de2267e443d8b790d4c8002922d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4b43b64dcf274516a60b06d6d316b73d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5063b43cb89a4b698844486edc2c6492","IPY_MODEL_5434d358a98f4ed587e478b93aa21332","IPY_MODEL_b1744ed786304665b1d014cc64448cb1"]}},"4b43b64dcf274516a60b06d6d316b73d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5063b43cb89a4b698844486edc2c6492":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_75e4e3c871964086a1ea84df87fcdb1e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 1 of 30:   0%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8f7f2f109710439b9e5710d558bba0aa"}},"5434d358a98f4ed587e478b93aa21332":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ed2c87c8a5a64f488cfb75b9dc34281b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":30,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_16747c60295342809300346cf809184e"}},"b1744ed786304665b1d014cc64448cb1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8c997e06b3f54aec805e66731f64b53d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/30 [00:02&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_03d9f2dca08641d98582da550e662c10"}},"75e4e3c871964086a1ea84df87fcdb1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8f7f2f109710439b9e5710d558bba0aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed2c87c8a5a64f488cfb75b9dc34281b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"16747c60295342809300346cf809184e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8c997e06b3f54aec805e66731f64b53d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"03d9f2dca08641d98582da550e662c10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5368ef16c20f41f0accc35ebca827a49":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7ba51f09def24a55958884a50016231c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0be9a1919eb941c0a39417addba9dcbd","IPY_MODEL_cf256ce1522a423bbf0ab8c4844c6f2b","IPY_MODEL_40c120a4ce304584a743d319fa965758"]}},"7ba51f09def24a55958884a50016231c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0be9a1919eb941c0a39417addba9dcbd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cacc94da1dbe4e4cb99a0da757ee573c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Running Epoch 0 of 30:   0%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f1b9457e9b3a4c14b85dde5811935cca"}},"cf256ce1522a423bbf0ab8c4844c6f2b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8351b890cacd48f2ac2a362284a8ecc1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":56,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_56e884c623c24dd0aacf90279c33f0f6"}},"40c120a4ce304584a743d319fa965758":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_91c847d9693b413596235831fac19f6b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/56 [00:02&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6ca198298c2147478a453cbf8fce67d8"}},"cacc94da1dbe4e4cb99a0da757ee573c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f1b9457e9b3a4c14b85dde5811935cca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8351b890cacd48f2ac2a362284a8ecc1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"56e884c623c24dd0aacf90279c33f0f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"91c847d9693b413596235831fac19f6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6ca198298c2147478a453cbf8fce67d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["Here we include the code for only_primary, dedup text. We'll use the pre-prepared Peter's files from the folder FastText2 (not the folder FastText4, where are also secondary labels (in every 3rd example))."],"metadata":{"id":"WXI_wZcXO9w1"}},{"cell_type":"markdown","source":["# Preparing the dataset"],"metadata":{"id":"83CAL5QvO9w2"}},{"cell_type":"markdown","source":["Code from utils.py. This code includes downsampling and experiments with secondary label."],"metadata":{"id":"oWu3oQmCO9w2"}},{"cell_type":"code","source":["!pip install -q parse"],"metadata":{"execution":{"iopub.status.busy":"2022-01-01T20:09:24.092955Z","iopub.execute_input":"2022-01-01T20:09:24.093869Z","iopub.status.idle":"2022-01-01T20:09:31.410867Z","shell.execute_reply.started":"2022-01-01T20:09:24.093824Z","shell.execute_reply":"2022-01-01T20:09:31.410037Z"},"trusted":true,"id":"757BzDWqO9w2","executionInfo":{"status":"ok","timestamp":1641208117374,"user_tz":-60,"elapsed":7054,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import json\n","import parse\n","#import fasttext\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import f1_score\n","\n","train_labels = ['__label__Legal/Regulation', '__label__Opinionated_News', '__label__News/Reporting', '__label__Forum', '__label__Correspondence', '__label__Invitation', '__label__Instruction', '__label__Recipe', '__label__Opinion/Argumentation', '__label__Promotion_of_Services', '__label__Promotion', '__label__List_of_Summaries/Excerpts', '__label__Promotion_of_a_Product', '__label__Call', '__label__Review', '__label__Other', '__label__Information/Explanation', '__label__Interview', '__label__Prose', '__label__Research_Article', '__label__Announcement']\n","STR_TO_NUM = {s: i for i, s in enumerate(train_labels)}\n","NUM_TO_STR = {i: s for i, s in enumerate(train_labels)}\n","NUM_TO_STR_NO_PREFIX = {i: s[9:].replace(\n","    \"_\", \" \") for i, s in enumerate(train_labels)}\n","train_labels_no_prefix = [s[9:].replace(\"_\", \" \") for s in train_labels]\n","\n","list_of_categories_matrix = ['Information/Explanation', 'Research Article', 'Instruction', 'Recipe', 'Legal/Regulation', 'Call', 'Announcement', 'News/Reporting', 'Opinionated News','Opinion/Argumentation', 'Review', 'Promotion', 'Promotion of a Product', 'Promotion of Services', 'Invitation', 'Forum', 'Interview', 'Correspondence', 'Prose', 'List of Summaries/Excerpts', 'Other']\n","\n","def parse_fasttext_file(path: str, encode=True):\n","    \"\"\"Reads fasttext formatted file and returns dataframe.\n","\n","    Args:\n","        path (str): fasttext file to be parsed.\n","        encode (bool, optional): Whether the labels should be encoded to integers. Defaults to True.\n","\n","    Returns:\n","        pd.DataFrame: DF with columns `text` and `labels`.\n","    \"\"\"\n","    with open(path, \"r\") as f:\n","        content = f.readlines()\n","    pattern = \"{label} {text}\\n\"\n","    p = parse.compile(pattern)\n","\n","    labels, texts = list(), list()\n","    for line in content:\n","        rez = p.parse(line)\n","        if rez is not None:\n","            if rez[\"label\"] == '__label__Promotion_of_services':\n","                labels.append('__label__Promotion_of_Services')\n","            elif rez[\"label\"] == '__label__Promotion_of_a_product':\n","                labels.append('__label__Promotion_of_a_Product')\n","            else:\n","                labels.append(rez[\"label\"])\n","            texts.append(rez[\"text\"])\n","        else:\n","            pass\n","    if encode:\n","        labels = [STR_TO_NUM[i] for i in labels]\n","    return pd.DataFrame(data={\"text\": texts, \"labels\": labels})"],"metadata":{"execution":{"iopub.status.busy":"2022-01-01T20:09:31.412921Z","iopub.execute_input":"2022-01-01T20:09:31.413229Z","iopub.status.idle":"2022-01-01T20:09:31.433033Z","shell.execute_reply.started":"2022-01-01T20:09:31.41319Z","shell.execute_reply":"2022-01-01T20:09:31.432149Z"},"trusted":true,"id":"_Bdpqnd_O9w3","executionInfo":{"status":"ok","timestamp":1641208118213,"user_tz":-60,"elapsed":844,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Prepare the model"],"metadata":{"id":"BSAKBizpO9w4"}},{"cell_type":"code","source":["# install simpletransformers\n","!pip install -q simpletransformers\n","\n","# check installed version\n","!pip freeze | grep simpletransformers"],"metadata":{"execution":{"iopub.status.busy":"2022-01-01T20:09:31.436209Z","iopub.execute_input":"2022-01-01T20:09:31.436561Z","iopub.status.idle":"2022-01-01T20:09:42.397466Z","shell.execute_reply.started":"2022-01-01T20:09:31.43652Z","shell.execute_reply":"2022-01-01T20:09:42.396543Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"eASAI17oO9w4","executionInfo":{"status":"ok","timestamp":1641208129841,"user_tz":-60,"elapsed":11631,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"}},"outputId":"79784256-a09d-4cd4-ca65-e725be60b8d5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["simpletransformers==0.63.3\n"]}]},{"cell_type":"markdown","source":["Argument use_multiprocessing = False is added to avoid the warning message: ``pt/conda/lib/python3.7/site-packages/simpletransformers/classification/classification_model.py:460: UserWarning: use_multiprocessing automatically disabled as camembert fails when using multiprocessing for feature conversion.``"],"metadata":{"id":"COLZkwxgO9w4"}},{"cell_type":"code","source":["def train_model(train_df, NUM_EPOCHS=30, num_labels=21, use_cuda=True, no_cache=True,\n","                labels=None):\n","    \"\"\"Trains a simpletransformer model and returns it.\n","\n","    Args:\n","        train_df (pandas.DataFrame): A DataFrame with columns [\"text\", \"labels\"].\n","        NUM_EPOCHS (int, optional): Number of epochs. Defaults to 30.\n","        num_labels (int, optional): Number of labels used. Defaults to 21.\n","        use_cuda (bool, optional): Whether to use cuda. Defaults to True. Set False for easier debugging.\n","        no_cache (bool, optional): Whether to use caching or not. Defaults to True.\n","        labels (list(str), optional): If not None, use these labels to use string labels instead of numeric labels. \n","            Defaults to None. If set, num_labels is calculated automatically.\n","\n","    Returns:\n","        simpletransformers.ClassificationModel: a trained model\n","    \"\"\"\n","    from simpletransformers.classification import ClassificationModel, ClassificationArgs\n","\n","    model_args = ClassificationArgs()\n","    model_args.num_train_epochs = NUM_EPOCHS\n","    model_args.learning_rate = 1e-5\n","    model_args.overwrite_output_dir = True\n","    model_args.train_batch_size = 32\n","    model_args.no_cache = no_cache\n","    model_args.no_save = True\n","    model_args.save_steps = -1\n","    model_args.max_seq_length = 390\n","    if labels:\n","        LABELS = list(LABELS)\n","        model_args.labels_list = LABELS\n","        num_labels = len(LABELS)\n","\n","    model = ClassificationModel(\n","        \"camembert\", \"EMBEDDIA/sloberta\",\n","        num_labels=num_labels,\n","        use_cuda=use_cuda,\n","        args=model_args\n","    )\n","    model.train_model(train_df)\n","    return model"],"metadata":{"execution":{"iopub.status.busy":"2022-01-01T20:10:38.940925Z","iopub.execute_input":"2022-01-01T20:10:38.941959Z","iopub.status.idle":"2022-01-01T20:10:38.950999Z","shell.execute_reply.started":"2022-01-01T20:10:38.941879Z","shell.execute_reply":"2022-01-01T20:10:38.949954Z"},"trusted":true,"id":"cvcpoo5NO9w5","executionInfo":{"status":"ok","timestamp":1641208129841,"user_tz":-60,"elapsed":17,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["dev_dd = \"/content/dev_onlyprimary_True_dedup_True_only_keep_False.fasttext\"\n","test_dd = \"/content/test_onlyprimary_True_dedup_True_only_keep_False.fasttext\"\n","train_dd = \"/content/train_onlyprimary_True_dedup_True.fasttext\""],"metadata":{"execution":{"iopub.status.busy":"2022-01-01T20:10:38.953081Z","iopub.execute_input":"2022-01-01T20:10:38.953581Z","iopub.status.idle":"2022-01-01T20:10:38.964807Z","shell.execute_reply.started":"2022-01-01T20:10:38.95354Z","shell.execute_reply":"2022-01-01T20:10:38.964096Z"},"trusted":true,"id":"YkKXzkxJO9w5","executionInfo":{"status":"ok","timestamp":1641208129842,"user_tz":-60,"elapsed":17,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["for filename in [ train_dd,  test_dd,  dev_dd]:\n","    try:\n","        _ = parse_fasttext_file(filename)\n","    except Exception as e:\n","        raise e"],"metadata":{"execution":{"iopub.status.busy":"2022-01-01T20:10:38.967817Z","iopub.execute_input":"2022-01-01T20:10:38.968293Z","iopub.status.idle":"2022-01-01T20:10:39.222498Z","shell.execute_reply.started":"2022-01-01T20:10:38.968259Z","shell.execute_reply":"2022-01-01T20:10:39.221779Z"},"trusted":true,"id":"KX7JT9FUO9w5","executionInfo":{"status":"ok","timestamp":1641208130211,"user_tz":-60,"elapsed":386,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["results = list()"],"metadata":{"execution":{"iopub.status.busy":"2022-01-01T20:10:39.223705Z","iopub.execute_input":"2022-01-01T20:10:39.223981Z","iopub.status.idle":"2022-01-01T20:10:39.228246Z","shell.execute_reply.started":"2022-01-01T20:10:39.223931Z","shell.execute_reply":"2022-01-01T20:10:39.227263Z"},"trusted":true,"id":"8RPhquxrO9w6","executionInfo":{"status":"ok","timestamp":1641208130213,"user_tz":-60,"elapsed":13,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["dev_dd_df = parse_fasttext_file(dev_dd)\n","test_dd_df = parse_fasttext_file(test_dd)\n","train_dd_df = parse_fasttext_file(train_dd)"],"metadata":{"execution":{"iopub.status.busy":"2022-01-01T20:10:39.230628Z","iopub.execute_input":"2022-01-01T20:10:39.231256Z","iopub.status.idle":"2022-01-01T20:10:39.479287Z","shell.execute_reply.started":"2022-01-01T20:10:39.231214Z","shell.execute_reply":"2022-01-01T20:10:39.478523Z"},"trusted":true,"id":"3ScitYf0O9w6","executionInfo":{"status":"ok","timestamp":1641208131021,"user_tz":-60,"elapsed":817,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["model = train_model(train_dd_df)"],"metadata":{"execution":{"iopub.status.busy":"2022-01-01T20:10:39.480562Z","iopub.execute_input":"2022-01-01T20:10:39.480822Z","iopub.status.idle":"2022-01-01T21:02:52.503299Z","shell.execute_reply.started":"2022-01-01T20:10:39.480787Z","shell.execute_reply":"2022-01-01T21:02:52.502557Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":566,"referenced_widgets":["2ba9de2267e443d8b790d4c8002922d7","4b43b64dcf274516a60b06d6d316b73d","5063b43cb89a4b698844486edc2c6492","5434d358a98f4ed587e478b93aa21332","b1744ed786304665b1d014cc64448cb1","75e4e3c871964086a1ea84df87fcdb1e","8f7f2f109710439b9e5710d558bba0aa","ed2c87c8a5a64f488cfb75b9dc34281b","16747c60295342809300346cf809184e","8c997e06b3f54aec805e66731f64b53d","03d9f2dca08641d98582da550e662c10","5368ef16c20f41f0accc35ebca827a49","7ba51f09def24a55958884a50016231c","0be9a1919eb941c0a39417addba9dcbd","cf256ce1522a423bbf0ab8c4844c6f2b","40c120a4ce304584a743d319fa965758","cacc94da1dbe4e4cb99a0da757ee573c","f1b9457e9b3a4c14b85dde5811935cca","8351b890cacd48f2ac2a362284a8ecc1","56e884c623c24dd0aacf90279c33f0f6","91c847d9693b413596235831fac19f6b","6ca198298c2147478a453cbf8fce67d8"]},"id":"YsY52_NUO9w6","executionInfo":{"status":"error","timestamp":1641208157824,"user_tz":-60,"elapsed":26811,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"}},"outputId":"454e207d-1a5d-4af5-f311-9d2d32f3adb8"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at EMBEDDIA/sloberta were not used when initializing CamembertForSequenceClassification: ['lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at EMBEDDIA/sloberta and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/simpletransformers/classification/classification_model.py:460: UserWarning: use_multiprocessing automatically disabled as camembert fails when using multiprocessing for feature conversion.\n","  f\"use_multiprocessing automatically disabled as {model_type}\"\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2ba9de2267e443d8b790d4c8002922d7","version_minor":0,"version_major":2},"text/plain":["Epoch:   0%|          | 0/30 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5368ef16c20f41f0accc35ebca827a49","version_minor":0,"version_major":2},"text/plain":["Running Epoch 0 of 30:   0%|          | 0/56 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_397/2694911190.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dd_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_397/775163348.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_df, NUM_EPOCHS, num_labels, use_cuda, no_cache, labels)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     )\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0meval_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         )\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataloader, output_dir, multi_label, show_running_loss, eval_df, test_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    883\u001b[0m                             \u001b[0mloss_fct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m                             \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m                         )\n\u001b[1;32m    887\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36m_calculate_loss\u001b[0;34m(self, model, inputs, loss_fct, num_labels, args)\u001b[0m\n\u001b[1;32m   2256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2258\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2259\u001b[0m         \u001b[0;31m# model outputs are always tuple in pytorch-transformers (see doc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2260\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1213\u001b[0m         )\n\u001b[1;32m   1214\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    531\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m                 )\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         )\n\u001b[1;32m    456\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2368\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2370\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 11.17 GiB total capacity; 10.43 GiB already allocated; 19.81 MiB free; 10.56 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"markdown","source":["# Evaluate the model"],"metadata":{"id":"BHqKUPIYO9w6"}},{"cell_type":"markdown","source":["Let's check if the model works:"],"metadata":{"id":"Bt_XaUvDO9w7"}},{"cell_type":"code","source":["predictions, raw_outputs = model.predict(['Danes poročamo o dogodku, ki se je zgodil 1. 1. 2020. Oseba je dejala:\"To je res nenormalen dogodek\"'])\n","\n","print(predictions)"],"metadata":{"execution":{"iopub.status.busy":"2022-01-01T21:02:52.504818Z","iopub.execute_input":"2022-01-01T21:02:52.505672Z","iopub.status.idle":"2022-01-01T21:02:52.94969Z","shell.execute_reply.started":"2022-01-01T21:02:52.505631Z","shell.execute_reply":"2022-01-01T21:02:52.948895Z"},"trusted":true,"id":"RctqCLeeO9w7","executionInfo":{"status":"aborted","timestamp":1641208157825,"user_tz":-60,"elapsed":11,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_true = test_dd_df.labels"],"metadata":{"execution":{"iopub.status.busy":"2022-01-01T21:02:52.951544Z","iopub.execute_input":"2022-01-01T21:02:52.952063Z","iopub.status.idle":"2022-01-01T21:02:52.957076Z","shell.execute_reply.started":"2022-01-01T21:02:52.952014Z","shell.execute_reply":"2022-01-01T21:02:52.956251Z"},"trusted":true,"id":"uTfJIjGOO9xB","executionInfo":{"status":"aborted","timestamp":1641208157826,"user_tz":-60,"elapsed":12,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["test_list_cleaned = test_dd_df.text.values.tolist()\n","\n","y_pred = []\n","\n","for text in test_list_cleaned:\n","  instance = []\n","  instance.append(text)\n","  y_pred_instance, raw_outputs = model.predict(instance)\n","  y_pred.append(y_pred_instance)"],"metadata":{"id":"kzxTszpsO9xB"}},{"cell_type":"markdown","source":["    microF1 = f1_score(y_true, y_pred, average=\"micro\")\n","    macroF1 = f1_score(y_true, y_pred, average=\"macro\")\n","    \n","    print(str(microF1), str(macroF1))"],"metadata":{"id":"KRqDv1XjO9xB"}},{"cell_type":"code","source":["def eval_model(test_df, model):\n","    \"\"\"Evaluates trained model on test_df and returns metrics.\n","\n","    Args:\n","        test_df (pd.DataFrame): dataframe with `text` and `labels` columns\n","        model (simpletransformers.ClassificationModel): previously trained model to evaluate.\n","\n","    Returns:\n","        results (dict): dictionary with fields `microF1`, `macroF1`, `y_true`, `y_pred`.\n","    \"\"\"\n","    y_true_enc = test_df.labels\n","    y_pred_enc = model.predict(test_df.text.tolist())[0]\n","\n","    y_true = [NUM_TO_STR[i] for i in y_true_enc]\n","    y_pred = [NUM_TO_STR[i] for i in y_pred_enc]\n","\n","    microF1 = f1_score(y_true, y_pred, labels=train_labels, average=\"micro\")\n","    macroF1 = f1_score(y_true, y_pred, labels=train_labels, average=\"macro\")\n","\n","    return {\"microF1\": microF1,\n","            \"macroF1\": macroF1,\n","            \"y_true\": y_true_enc.tolist(),\n","            \"y_pred\": y_pred_enc.tolist()}\n"],"metadata":{"execution":{"iopub.status.busy":"2022-01-01T21:07:23.336957Z","iopub.execute_input":"2022-01-01T21:07:23.337508Z","iopub.status.idle":"2022-01-01T21:07:23.359212Z","shell.execute_reply.started":"2022-01-01T21:07:23.33747Z","shell.execute_reply":"2022-01-01T21:07:23.358442Z"},"trusted":true,"id":"v40eL2aTO9xC","executionInfo":{"status":"aborted","timestamp":1641208157827,"user_tz":-60,"elapsed":13,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eval_model(test_dd_df,model)"],"metadata":{"id":"tzReCXGlP5Wu","executionInfo":{"status":"aborted","timestamp":1641208157828,"user_tz":-60,"elapsed":48371,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_cm(y_true, y_pred,  save=False, title=None, labels=None,\n","            include_metrics=True, figsize=None):\n","    \"\"\"Plots confusion matrix for y_true and y_pred. Can calculate\n","    metrics and display them in the title.\n","\n","    Args:\n","        y_true (list|np.array|pd.Series): true labels\n","        y_pred (list|np.array|pd.Series): predicted labels\n","        save (bool|str, optional): string, path to save a figure to, or bool (False) to not save. Defaults to False.\n","        title ([None|str], optional): Title to put at the top of the figure. Defaults to None.\n","        labels (list|np.array|pd.Series, optional): how to arrange labels. The list must contain all labels\n","            that appear in y_true and y_pred. Defaults to None.\n","        include_metrics (bool, optional): Whether the metrics should be displayed\n","            under the title. Defaults to True.\n","        figsize (tuple(int, int), optional): figure size. Defaults to None.\n","\n","    Returns:\n","        microF1, macroF1: metrics.\n","    \"\"\"            \n","    from sklearn.metrics import confusion_matrix\n","    from sklearn.metrics import f1_score\n","    import matplotlib.pyplot as plt\n","    if not labels:\n","        labels = list_of_categories_matrix\n","    plt.style.use([\"science\", \"no-latex\", ])\n","    cm = confusion_matrix(y_true, y_pred, labels=labels, )\n","    cm = cm/3\n","    cm = cm.astype(int)\n","    # print(cm)\n","    if figsize == None:\n","        figsize = (9, 9)\n","    plt.figure(figsize=figsize)\n","    plt.imshow(cm, cmap=\"Oranges\")\n","    for (i, j), z in np.ndenumerate(cm):\n","        plt.text(j, i, '{:d}'.format(z), ha='center', va='center')\n","    classNames = labels\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    tick_marks = np.arange(len(classNames))\n","    plt.xticks(tick_marks, classNames, rotation=90)\n","    plt.yticks(tick_marks, classNames)\n","    microF1 = f1_score(y_true, y_pred, labels=labels, average=\"micro\")\n","    macroF1 = f1_score(y_true, y_pred, labels=labels, average=\"macro\")\n","\n","    print(f\"{microF1:0.4}\")\n","    print(f\"{macroF1:0.4}\")\n","\n","    metrics = f\"{microF1:0.4}, {macroF1:0.4}\" if include_metrics else \"\"\n","    if title:\n","        if include_metrics:\n","            plt.title(title + \";\\n\" + metrics)\n","        else:\n","            plt.title(title)\n","    else:\n","        plt.title(metrics)\n","    plt.tight_layout()\n","    if save:\n","        plt.savefig(save)\n","    plt.show()\n","    return microF1, macroF1\n","\n","\n","def read_record(filename: str) -> pd.DataFrame:\n","    \"\"\"Reads a record file and returns a DataFrame.\n","\n","    Args:\n","        filename (str): record filename\n","\n","    Returns:\n","        pd.DataFrame: resulting dataframe\n","    \"\"\"\n","    import json\n","    import pandas as pd\n","    pd.set_option(\"precision\", 3)\n","    with open(filename) as f:\n","        content = json.load(f)\n","    jsonlikecontent = dict()\n","    for key in content[0].keys():\n","        jsonlikecontent[key] = [i[key] for i in content]\n","    df = pd.DataFrame(data=jsonlikecontent)\n","    return df\n","\n","\n","def to_label(l: list, reduced=False) -> list:\n","    \"\"\"Transform a series of strings or integers into original labels.\n","\n","    Args:\n","        l (list): list or pandas.Series with either string or numeric labels.\n","        reduced (bool, optional): if True, use reduced label set (12 labels). Defaults to False.\n","\n","    Raises:\n","        AttributeError: there seems to be a weird input type\n","\n","    Returns:\n","        list: list of labels with no prefix\n","    \"\"\"    \n","    \n","    to_return = list()\n","    for i in l:\n","        if type(i) == int:\n","            to_return.append(NUM_TO_STR_NO_PREFIX[i])\n","        elif type(i) == str:\n","            to_return.append(i[9:].replace(\"_\", \" \"))\n","        else:\n","            raise AttributeError(f\"Got type {type(i)} for input {i}\")\n","    return to_return"],"metadata":{"id":"kBJ5oEKcP3eN","executionInfo":{"status":"aborted","timestamp":1641208157829,"user_tz":-60,"elapsed":48367,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rundict = eval_model(test_dd_df, model)\n","rundict[\"train\"] = \"baseline_dd\"\n","rundict[\"eval\"] = \"test_dd\"\n","results.append(rundict)\n","\n","with open(\"backup_1.txt\", \"w\") as f:\n","    json.dump(results, f)"],"metadata":{"execution":{"iopub.status.busy":"2022-01-01T21:07:23.360415Z","iopub.execute_input":"2022-01-01T21:07:23.360689Z","iopub.status.idle":"2022-01-01T21:07:37.912779Z","shell.execute_reply.started":"2022-01-01T21:07:23.36066Z","shell.execute_reply":"2022-01-01T21:07:37.912026Z"},"trusted":true,"id":"JnWAcfexO9xC","executionInfo":{"status":"aborted","timestamp":1641208158064,"user_tz":-60,"elapsed":1,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"}}},"execution_count":null,"outputs":[]}]}