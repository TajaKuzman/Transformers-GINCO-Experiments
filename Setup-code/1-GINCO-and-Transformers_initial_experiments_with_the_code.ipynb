{"cells":[{"cell_type":"markdown","metadata":{"id":"lQtB43PuAD2H"},"source":["# Preparing the dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-01-03T13:10:39.695476Z","iopub.status.busy":"2022-01-03T13:10:39.695203Z","iopub.status.idle":"2022-01-03T13:10:39.875903Z","shell.execute_reply":"2022-01-03T13:10:39.875075Z","shell.execute_reply.started":"2022-01-03T13:10:39.695449Z"},"executionInfo":{"elapsed":389,"status":"ok","timestamp":1640949108560,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"},"user_tz":-60},"id":"qL9iYqif_lSk","trusted":true},"outputs":[],"source":["# Import the file\n","import json\n","\n","with open(\"/kaggle/input/genre-identification-corpus-ginco-10/GINCO-1.0-suitable.json\") as f:\n","    dataset = json.load(f)\n","\n","dataset[0]"]},{"cell_type":"markdown","metadata":{"id":"qn5ISqRR3hpq"},"source":[" ## Extract text from paragraphs into one string\n","\n"," We'll create two additional parameters for each text: \"full_text\" with text from all parameters, and \"dedup_text\" with text from the deduplicated paragraphs only (no near-duplicates)."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-01-03T13:11:21.102689Z","iopub.status.busy":"2022-01-03T13:11:21.101832Z","iopub.status.idle":"2022-01-03T13:11:21.124685Z","shell.execute_reply":"2022-01-03T13:11:21.123914Z","shell.execute_reply.started":"2022-01-03T13:11:21.102639Z"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1640949108561,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"},"user_tz":-60},"id":"T9jzjZSc3GX1","trusted":true},"outputs":[],"source":["for instance in dataset:\n","    paragraphs = instance[\"paragraphs\"]\n","\n","    # Joining texts:\n","    instance_full_text = \" <p/> \".join([p[\"text\"] for p in paragraphs])\n","\n","    # Assigning texts to a new field:\n","    instance[\"full_text\"] = instance_full_text\n","\n","for instance in dataset:\n","    paragraphs = instance[\"paragraphs\"]\n","    # Removing duplicates:\n","    paragraphs = [p for p in paragraphs if not p[\"duplicate\"]]\n","\n","    # Joining texts:\n","    instance_dedup_text = \" <p/> \".join([p[\"text\"] for p in paragraphs])\n","\n","    # Assigning texts to a new field:\n","    instance[\"dedup_text\"] = instance_dedup_text\n","\n","dataset[0]"]},{"cell_type":"markdown","metadata":{"id":"glWTirdA5MU6"},"source":["## Create the test-train-dev split"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-01-03T13:11:41.465329Z","iopub.status.busy":"2022-01-03T13:11:41.465052Z","iopub.status.idle":"2022-01-03T13:11:41.473567Z","shell.execute_reply":"2022-01-03T13:11:41.472580Z","shell.execute_reply.started":"2022-01-03T13:11:41.465297Z"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1640949108562,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"},"user_tz":-60},"id":"HkxE4j5A5HQt","outputId":"ed3a4a61-8077-4f8b-a57d-1839e979de5b","trusted":true},"outputs":[],"source":["train = [i for i in dataset if i[\"split\"] == \"train\"]\n","test = [i for i in dataset if i[\"split\"] == \"test\"]\n","dev = [i for i in dataset if i[\"split\"] == \"dev\"]\n","\n","print(\"The train-dev-test splits consist of the following numbers of examples:\", len(train), len(test), len(dev))"]},{"cell_type":"markdown","metadata":{"id":"xw1ugH8i6KuD"},"source":["## Transform the dataset in tabular form"]},{"cell_type":"markdown","metadata":{"id":"3o7RaayZBY7s"},"source":["As simpletransformers expects a pandas dataframe input, we now construct a DataFrame with columns text and labels.\n","\n","For labels we will use the primary_level_2 label and for the text, we'll use the deduplicated text."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-01-03T13:12:02.493860Z","iopub.status.busy":"2022-01-03T13:12:02.493452Z","iopub.status.idle":"2022-01-03T13:12:02.513209Z","shell.execute_reply":"2022-01-03T13:12:02.512632Z","shell.execute_reply.started":"2022-01-03T13:12:02.493822Z"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1640949108562,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"},"user_tz":-60},"id":"4APwEqqG5nF-","trusted":true},"outputs":[],"source":["import pandas as pd\n","train_df = pd.DataFrame(data=train, columns=[\"dedup_text\", \"primary_level_2\"])\n","# Renaming columns to `text` and `labels`\n","train_df.columns = [\"text\", \"labels\"]\n","\n","# Let's look at the beginning of the train dataframe\n","\n","train_df.head()"]},{"cell_type":"markdown","metadata":{"id":"bpdXwJ76CQng"},"source":["We will need to specify the exact number of labels, so we calculate it from our dataframe."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-01-03T13:12:09.001907Z","iopub.status.busy":"2022-01-03T13:12:09.001298Z","iopub.status.idle":"2022-01-03T13:12:09.015478Z","shell.execute_reply":"2022-01-03T13:12:09.014643Z","shell.execute_reply.started":"2022-01-03T13:12:09.001857Z"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1640949108563,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"},"user_tz":-60},"id":"1boL1xOFCSUc","outputId":"849f6aa4-b7e9-43b8-ffea-27fc49f91118","trusted":true},"outputs":[],"source":["LABELS = train_df.labels.unique().tolist()\n","NUM_LABELS = len(LABELS)\n","NUM_LABELS"]},{"cell_type":"markdown","metadata":{"id":"4Kx0NqxXE6vw"},"source":["Repeat the process with the test and dev split:"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-01-03T13:12:28.975500Z","iopub.status.busy":"2022-01-03T13:12:28.974871Z","iopub.status.idle":"2022-01-03T13:12:28.987847Z","shell.execute_reply":"2022-01-03T13:12:28.987006Z","shell.execute_reply.started":"2022-01-03T13:12:28.975439Z"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1640949108563,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"},"user_tz":-60},"id":"Hr30_WeJE_Bt","trusted":true},"outputs":[],"source":["test_df = pd.DataFrame(data=test, columns=[\"dedup_text\", \"primary_level_2\"])\n","test_df.columns = [\"text\", \"labels\"]\n","test_df.tail()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-01-03T13:12:55.844266Z","iopub.status.busy":"2022-01-03T13:12:55.843961Z","iopub.status.idle":"2022-01-03T13:12:55.855933Z","shell.execute_reply":"2022-01-03T13:12:55.854982Z","shell.execute_reply.started":"2022-01-03T13:12:55.844233Z"},"trusted":true},"outputs":[],"source":["dev_df = pd.DataFrame(data=dev, columns=[\"dedup_text\", \"primary_level_2\"])\n","dev_df.columns = [\"text\", \"labels\"]\n","dev_df.tail()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-01-03T13:13:11.314214Z","iopub.status.busy":"2022-01-03T13:13:11.313935Z","iopub.status.idle":"2022-01-03T13:13:11.392187Z","shell.execute_reply":"2022-01-03T13:13:11.391379Z","shell.execute_reply.started":"2022-01-03T13:13:11.314184Z"},"trusted":true},"outputs":[],"source":["# Save the dataframe to a csv:\n","train_df.to_csv(\"GINCO_dataframe_dedup_train.csv\", index=False)\n","test_df.to_csv(\"GINCO_dataframe_dedup_test.csv\", index=False)"]},{"cell_type":"markdown","metadata":{},"source":["Merge train to dev to get bigger train data:"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-01-03T13:14:55.578716Z","iopub.status.busy":"2022-01-03T13:14:55.578418Z","iopub.status.idle":"2022-01-03T13:14:55.585917Z","shell.execute_reply":"2022-01-03T13:14:55.585393Z","shell.execute_reply.started":"2022-01-03T13:14:55.578683Z"},"trusted":true},"outputs":[],"source":["train_dev_df = pd.concat([train_df, dev_df], ignore_index=True)\n","train_dev_df.shape"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-01-03T13:15:21.956048Z","iopub.status.busy":"2022-01-03T13:15:21.955321Z","iopub.status.idle":"2022-01-03T13:15:22.032779Z","shell.execute_reply":"2022-01-03T13:15:22.031958Z","shell.execute_reply.started":"2022-01-03T13:15:21.956005Z"},"trusted":true},"outputs":[],"source":["# Save the dataframe to a csv:\n","train_dev_df.to_csv(\"GINCO_dataframe_dedup_train_dev.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"tmYURDJHCbRT"},"source":["# Training the baseline - SloBERTa"]},{"cell_type":"markdown","metadata":{"id":"9rLWz4ZPR3G6"},"source":["Resources:\n","- https://towardsdatascience.com/bert-text-classification-in-a-different-language-6af54930f9cb\n","- Peter's demo code: https://github.com/TajaKuzman/Transformers-GINCO-Experiments/blob/main/Peters-code/Peter-GINCO-demo.ipynb\n","- Peter's final code (for the LREC article): https://github.com/5roop/task5_webgenres/"]},{"cell_type":"markdown","metadata":{"id":"NAsW9gmZCt0k"},"source":["We will use the hyperparameters from the article *The GINCO Training Dataset for Web Genre Identification of Documents Out in the Wild* as the hyperparameter search revealed them to be the most suitable for the task. That is, the models will be trained for 30 epochs with the learning rate of 10^-5. The sequence length of 512 tokens will be used."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12067,"status":"ok","timestamp":1640949120624,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"},"user_tz":-60},"id":"maK2UIUjEQyB","outputId":"4e5de5bb-7938-4fd5-b700-d4797f2b5475"},"outputs":[],"source":["# install simpletransformers\n","!pip install -q simpletransformers\n","\n","# check installed version\n","!pip freeze | grep simpletransformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MZ-0GdV-Ccns"},"outputs":[],"source":["from simpletransformers.classification import ClassificationModel, ClassificationArgs\n","\n","\n","model_args = ClassificationArgs()\n","\n","model_args.num_train_epochs = 30\n","model_args.learning_rate = 1e-5\n","model_args.overwrite_output_dir = True\n","model_args.train_batch_size = 32\n","model_args.no_cache = True\n","model_args.no_save = True\n","model_args.fp16 = False\n","model_args.save_steps = -1\n","model_args.max_seq_length = 512\n","model_args.labels_list = LABELS\n","\n","\n","model = ClassificationModel(\"camembert\", \"EMBEDDIA/sloberta\",\n","                            num_labels = NUM_LABELS,\n","                            use_cuda = True,\n","                            args = model_args,\n","                            )\n","model.train_model(train_df)"]},{"cell_type":"markdown","metadata":{"id":"1fqqBKSB2Vea"},"source":["There are some issues with the model. I've checked whether Google Colab otherwise works with simple transformers (using an example from a BERT tutorial), and it does."]},{"cell_type":"markdown","metadata":{"id":"HATgrpdgC4q1"},"source":["Working with this setting worked, so we must find out which of the settings in the initial code produced an error."]},{"cell_type":"markdown","metadata":{"id":"fH9Th9keFPIl"},"source":["First, I've muted additional parameters from the BERT tutorial. The code worked, so I deleted them."]},{"cell_type":"markdown","metadata":{"id":"_hbu7RVaDEW5"},"source":["1. Overwrite_output_dir - okay\n","2. Num_train_epochs - okay\n","3. labels_list - okay\n","4. learning_rate - okay\n","5. train_batch_size - okay\n","6. no_cache - okay\n","7. no_save - okay\n","8. save_steps - okay\n","\n","--> the problem is in the parameter **\"max_seq_length\": 512** Using this parameter requires more GPU memory that is available in the Kaggle and Google Colab environment -> we must go with smaller max_seq_length size (such that works for all model, even the large-sized one.)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
