{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Import all necessary libraries and install everything you need for training:","metadata":{}},{"cell_type":"code","source":"# install pytorch\n!conda install --yes pytorch>=1.6 cudatoolkit=11.0 -c pytorch","metadata":{"execution":{"iopub.status.busy":"2022-01-03T20:48:59.58043Z","iopub.execute_input":"2022-01-03T20:48:59.581034Z","iopub.status.idle":"2022-01-03T20:50:30.637361Z","shell.execute_reply.started":"2022-01-03T20:48:59.580941Z","shell.execute_reply":"2022-01-03T20:50:30.635936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# install simpletransformers\n!pip install -q transformers\n!pip install --upgrade transformers\n!pip install -q simpletransformers\n\n# check installed version\n!pip freeze | grep simpletransformers","metadata":{"execution":{"iopub.status.busy":"2022-01-03T20:50:30.641146Z","iopub.execute_input":"2022-01-03T20:50:30.641564Z","iopub.status.idle":"2022-01-03T20:51:08.557503Z","shell.execute_reply.started":"2022-01-03T20:50:30.641532Z","shell.execute_reply":"2022-01-03T20:51:08.556496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# install stable torch\n!pip uninstall -q torch -y\n!pip install -q torch==1.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html","metadata":{"execution":{"iopub.status.busy":"2022-01-03T20:51:08.559303Z","iopub.execute_input":"2022-01-03T20:51:08.559585Z","iopub.status.idle":"2022-01-03T20:52:30.782128Z","shell.execute_reply.started":"2022-01-03T20:51:08.559557Z","shell.execute_reply":"2022-01-03T20:52:30.779769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# install the libraries necessary for data wrangling, prediction and result analysis\nfrom sklearn.metrics import f1_score, ConfusionMatrixDisplay, confusion_matrix, accuracy_score\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-01-03T20:52:30.78798Z","iopub.execute_input":"2022-01-03T20:52:30.790778Z","iopub.status.idle":"2022-01-03T20:52:31.957907Z","shell.execute_reply.started":"2022-01-03T20:52:30.790732Z","shell.execute_reply":"2022-01-03T20:52:31.957164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import the data","metadata":{}},{"cell_type":"code","source":"# Import the data, prepared for the experiments\ntrain_df = pd.read_csv(\"/kaggle/input/gincodataframededuptraindevtest/GINCO_dataframe_dedup_train_dev.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/gincodataframededuptraindevtest/GINCO_dataframe_dedup_test.csv\")\n\nprint(\"Train shape: {}, Test shape: {}.\".format(train_df.shape, test_df.shape))","metadata":{"execution":{"iopub.status.busy":"2022-01-03T20:52:31.959132Z","iopub.execute_input":"2022-01-03T20:52:31.959381Z","iopub.status.idle":"2022-01-03T20:52:32.864779Z","shell.execute_reply.started":"2022-01-03T20:52:31.959348Z","shell.execute_reply":"2022-01-03T20:52:32.862991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a list of labels\nLABELS = train_df.labels.unique().tolist()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T20:52:32.873684Z","iopub.execute_input":"2022-01-03T20:52:32.87826Z","iopub.status.idle":"2022-01-03T20:52:32.895626Z","shell.execute_reply.started":"2022-01-03T20:52:32.878209Z","shell.execute_reply":"2022-01-03T20:52:32.894394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the instances with no text\ntrain_df = train_df.dropna()\ntest_df = test_df.dropna()\nprint(\"Train shape: {}, Test shape: {}.\".format(train_df.shape, test_df.shape))","metadata":{"execution":{"iopub.status.busy":"2022-01-03T20:52:32.90332Z","iopub.execute_input":"2022-01-03T20:52:32.906888Z","iopub.status.idle":"2022-01-03T20:52:33.203896Z","shell.execute_reply.started":"2022-01-03T20:52:32.906828Z","shell.execute_reply":"2022-01-03T20:52:33.203106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transformers","metadata":{}},{"cell_type":"markdown","source":"Let's start with arguments which are the same for all the models.","metadata":{}},{"cell_type":"code","source":"# define hyperparameters\nmodel_args ={\"overwrite_output_dir\": True,\n             \"num_train_epochs\": 90,\n             \"labels_list\": LABELS,\n             \"learning_rate\": 1e-5,\n             \"train_batch_size\": 32,\n             \"no_cache\": True,\n             \"no_save\": True,\n             \"max_seq_length\": 300,\n             \"save_steps\": -1,\n             }","metadata":{"execution":{"iopub.status.busy":"2022-01-03T20:52:33.205165Z","iopub.execute_input":"2022-01-03T20:52:33.206091Z","iopub.status.idle":"2022-01-03T20:52:33.293194Z","shell.execute_reply.started":"2022-01-03T20:52:33.20605Z","shell.execute_reply":"2022-01-03T20:52:33.292399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nimport torch\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T20:52:33.296814Z","iopub.execute_input":"2022-01-03T20:52:33.297314Z","iopub.status.idle":"2022-01-03T20:52:34.097381Z","shell.execute_reply.started":"2022-01-03T20:52:33.297276Z","shell.execute_reply":"2022-01-03T20:52:34.096614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SloBERTa\nSlovene model\nhttps://huggingface.co/EMBEDDIA/sloberta","metadata":{}},{"cell_type":"code","source":"from simpletransformers.classification import ClassificationModel\n\nsloberta_model = ClassificationModel(\n    \"camembert\", \"EMBEDDIA/sloberta\",\n    use_cuda = True,\n    num_labels = 21,\n    args = model_args)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T20:52:34.098829Z","iopub.execute_input":"2022-01-03T20:52:34.099069Z","iopub.status.idle":"2022-01-03T20:53:09.902881Z","shell.execute_reply.started":"2022-01-03T20:52:34.099036Z","shell.execute_reply":"2022-01-03T20:53:09.901008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CroSloEngual BERT\nSlovene-Croatian-English model\nhttps://huggingface.co/EMBEDDIA/crosloengual-bert","metadata":{}},{"cell_type":"markdown","source":"from simpletransformers.classification import ClassificationModel\n\ncrosloengualbert_model = ClassificationModel(\n        \"bert\", \"EMBEDDIA/crosloengual-bert\",\n        num_labels=21,\n        use_cuda=True,\n        args=model_args\n    )","metadata":{"execution":{"iopub.status.busy":"2022-01-03T18:56:58.240818Z","iopub.execute_input":"2022-01-03T18:56:58.241098Z","iopub.status.idle":"2022-01-03T18:57:04.424455Z","shell.execute_reply.started":"2022-01-03T18:56:58.241066Z","shell.execute_reply":"2022-01-03T18:57:04.42367Z"}}},{"cell_type":"markdown","source":"### Base-sized XLM-RoBERTa\n\nMultilingual model\nhttps://huggingface.co/xlm-roberta-base","metadata":{}},{"cell_type":"markdown","source":"from simpletransformers.classification import ClassificationModel\n\nroberta_base_model = ClassificationModel(\n        \"xlmroberta\", \"xlm-roberta-base\",\n        num_labels=21,\n        use_cuda=True,\n        args=model_args\n    )","metadata":{"execution":{"iopub.status.busy":"2022-01-03T19:10:57.479779Z","iopub.execute_input":"2022-01-03T19:10:57.480105Z","iopub.status.idle":"2022-01-03T19:11:58.274814Z","shell.execute_reply.started":"2022-01-03T19:10:57.480071Z","shell.execute_reply":"2022-01-03T19:11:58.273784Z"}}},{"cell_type":"markdown","source":"### Large-sized XML-RoBERTa\nMultilingual model https://huggingface.co/xlm-roberta-large","metadata":{}},{"cell_type":"markdown","source":"from simpletransformers.classification import ClassificationModel\n\nroberta_large_model = ClassificationModel(\n        \"xlmroberta\", \"xlm-roberta-large\",\n        num_labels=21,\n        use_cuda=True,\n        args=model_args\n    )","metadata":{"execution":{"iopub.status.busy":"2022-01-03T20:07:36.13473Z","iopub.execute_input":"2022-01-03T20:07:36.136909Z","iopub.status.idle":"2022-01-03T20:07:50.811525Z","shell.execute_reply.started":"2022-01-03T20:07:36.136868Z","shell.execute_reply":"2022-01-03T20:07:50.809439Z"}}},{"cell_type":"markdown","source":"### DeBERTaV3\nMultilingual model https://huggingface.co/microsoft/mdeberta-v3-base","metadata":{}},{"cell_type":"markdown","source":"from simpletransformers.classification import ClassificationModel\n\ndebertav3_model = ClassificationModel(\n        \"debertav2\", \"microsoft/mdeberta-v3-base\",\n        num_labels=21,\n        use_cuda=True,\n        args=model_args\n    )","metadata":{"execution":{"iopub.status.busy":"2022-01-03T19:25:30.459204Z","iopub.execute_input":"2022-01-03T19:25:30.462074Z","iopub.status.idle":"2022-01-03T19:25:42.477123Z","shell.execute_reply.started":"2022-01-03T19:25:30.462035Z","shell.execute_reply":"2022-01-03T19:25:42.476282Z"}}},{"cell_type":"markdown","source":"### BERTić\nModel for related South Slavic languages https://huggingface.co/classla/bcms-bertic","metadata":{}},{"cell_type":"markdown","source":"from simpletransformers.classification import ClassificationModel\n\nbertic_model = ClassificationModel(\n        \"electra\", \"classla/bcms-bertic\",\n        num_labels=21,\n        use_cuda=True,\n        args=model_args\n    )","metadata":{"execution":{"iopub.status.busy":"2022-01-03T20:12:05.456734Z","iopub.execute_input":"2022-01-03T20:12:05.457033Z","iopub.status.idle":"2022-01-03T20:12:32.68296Z","shell.execute_reply.started":"2022-01-03T20:12:05.45699Z","shell.execute_reply":"2022-01-03T20:12:32.682204Z"}}},{"cell_type":"markdown","source":"### BERT base model (cased)\nMonolingual English model https://huggingface.co/bert-base-cased","metadata":{}},{"cell_type":"markdown","source":"from simpletransformers.classification import ClassificationModel\n\nbertbase_model = ClassificationModel(\n        \"bert\", \"bert-base-cased\",\n        num_labels=21,\n        use_cuda=True,\n        args=model_args\n    )","metadata":{"execution":{"iopub.status.busy":"2022-01-03T20:17:26.277703Z","iopub.execute_input":"2022-01-03T20:17:26.27795Z","iopub.status.idle":"2022-01-03T20:17:34.462616Z","shell.execute_reply.started":"2022-01-03T20:17:26.277915Z","shell.execute_reply":"2022-01-03T20:17:34.461738Z"}}},{"cell_type":"markdown","source":"## Training and evaluation","metadata":{}},{"cell_type":"markdown","source":"### Train","metadata":{}},{"cell_type":"code","source":"# SloBERTa\nsloberta_model.train_model(train_df)\n\n# CroSloEngual BERT\n#crosloengualbert_model.train_model(train_df)\n\n# Base-sized XML-Roberta\n#roberta_base_model.train_model(train_df)\n\n# Large-sized XML-Roberta\n#roberta_large_model.train_model(train_df)\n\n# DeBERTav3\n#debertav3_model.train_model(train_df)\n\n# BERTić\n#bertic_model.train_model(train_df)\n\n# English base-sized BERT\n#bertbase_model.train_model(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T20:53:09.904534Z","iopub.execute_input":"2022-01-03T20:53:09.904813Z","iopub.status.idle":"2022-01-03T21:30:08.41898Z","shell.execute_reply.started":"2022-01-03T20:53:09.904774Z","shell.execute_reply":"2022-01-03T21:30:08.418303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate","metadata":{}},{"cell_type":"code","source":"def eval_model(model,plot_title=None):\n    \"\"\" Evaluates the model. It takes the test data, named as \"test_df\", and labels list named \"LABELS\".\n    \n    Args: \n        model (simpletransformers.ClassificationModel): the model name.\n        plot_title (string): the title of the confusion matrix, defaults to None.\n    \n    Returns:\n        results (dict): dictionary with fields `plot_title`, `microF1`, `macroF1`, `y_true`, `y_pred`.    \n    \"\"\"\n    instance_predictions, raw_outputs = sloberta_model.predict(['Danes poročamo o dogodku, ki se je zgodil 1. 1. 2020. Oseba je dejala:\"To je res nenormalen dogodek\"'])\n    print(\"Instance prediction: \", instance_predictions)\n    \n    # Get the true labels from the dataframe\n    y_true = test_df.labels\n\n    # Calculate the model's predictions\n    y_pred = model.predict(test_df.text.tolist())[0]\n    \n    macro = f1_score(y_true, y_pred, labels=LABELS, average=\"macro\")\n    micro = f1_score(y_true, y_pred, labels=LABELS,  average=\"micro\")\n    print(f\"Macro f1: {macro:0.3}\\nMicro f1: {micro:0.3}\")\n      \n    cm = confusion_matrix(y_true, y_pred, labels=LABELS)\n    plt.figure(figsize=(9, 9))\n    plt.imshow(cm, cmap=\"Oranges\")\n    for (i, j), z in np.ndenumerate(cm):\n        plt.text(j, i, '{:d}'.format(z), ha='center', va='center')\n    classNames = LABELS\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    tick_marks = np.arange(len(classNames))\n    plt.xticks(tick_marks, classNames, rotation=90)\n    plt.yticks(tick_marks, classNames)\n\n    metrics = f\"{micro:0.3}, {macro:0.3}\"\n    if plot_title:\n        plt.title(plot_title +\";\\n\" + metrics)\n    else:\n        plt.title(metrics)\n    plt.tight_layout()\n    plt.show()\n    return {\"Run\": plot_title,\n            \"microF1\": micro,\n            \"macroF1\": macro,\n            \"y_true\": y_true.tolist(),\n            \"y_pred\": y_pred}","metadata":{"execution":{"iopub.status.busy":"2022-01-03T21:54:20.351124Z","iopub.execute_input":"2022-01-03T21:54:20.351402Z","iopub.status.idle":"2022-01-03T21:54:20.364048Z","shell.execute_reply.started":"2022-01-03T21:54:20.351369Z","shell.execute_reply":"2022-01-03T21:54:20.363045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Choose from the following models:\nsloberta_model(train_df), crosloengualbert_model(train_df), roberta_base_model(train_df), roberta_large_model(train_df), debertav3_model(train_df), bertic_model(train_df), bertbase_model(train_df)","metadata":{}},{"cell_type":"code","source":"rundict = eval_model(sloberta_model,plot_title=\"SloBERTa_1st_run\")","metadata":{"execution":{"iopub.status.busy":"2022-01-03T22:00:37.280198Z","iopub.execute_input":"2022-01-03T22:00:37.280543Z","iopub.status.idle":"2022-01-03T22:00:37.363803Z","shell.execute_reply.started":"2022-01-03T22:00:37.280462Z","shell.execute_reply":"2022-01-03T22:00:37.362856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.savefig(\"SloBERTa_1st_run.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-01-03T21:59:36.734974Z","iopub.execute_input":"2022-01-03T21:59:36.735239Z","iopub.status.idle":"2022-01-03T21:59:36.751909Z","shell.execute_reply.started":"2022-01-03T21:59:36.735211Z","shell.execute_reply":"2022-01-03T21:59:36.750964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(rundict)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T21:56:55.729244Z","iopub.execute_input":"2022-01-03T21:56:55.729522Z","iopub.status.idle":"2022-01-03T21:56:55.733644Z","shell.execute_reply.started":"2022-01-03T21:56:55.72949Z","shell.execute_reply":"2022-01-03T21:56:55.732955Z"},"trusted":true},"execution_count":null,"outputs":[]}]}