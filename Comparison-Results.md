# The Results of the Transformer Comparison

1. SloBERTa:
* 1st run: Macro f1: 0.531, Micro f1: 0.619
* 2nd run: Macro f1: 0.592, Micro f1: 0.624
* 3rd run: Macro f1: 0.572, Micro f1: 0.594
* 4th run: Macro f1: 0.522, Micro f1: 0.599
* 5th run: Macro f1: 0.539, Micro f1: 0.609

2. CroSloEngual BERT:
* 1st run: Macro f1: 0.374, Micro f1: 0.518
* 2nd run: Macro f1: 0.454, Micro f1: 0.508
* 3rd run: Macro f1: 0.379, Micro f1: 0.503
* 4th run: Macro f1: 0.388, Micro f1: 0.497
* 5th run: Macro f1: 0.462, Micro f1: 0.548

3. XML-RoBERTa Base:
* 1st run: Macro f1: 0.518, Micro f1: 0.523
* 2nd run: Macro f1: 0.557, Micro f1: 0.558
* 3rd run: Macro f1: 0.57, Micro f1: 0.563
* 4th run: Macro f1: 0.559, Micro f1: 0.569
* 5th run: Macro f1: 0.556, Micro f1: 0.558

4. mDeBERTaV3 (??? - error, assigning all instances to one class (Research Article, Invitation) Macro f1: 0.00327, Micro f1: 0.0355)

5. BERTiÄ‡:
* 1st run: Macro f1: 0.379, Micro f1: 0.472
* 2nd run: Macro f1: 0.488, Micro f1: 0.492
* 3rd run: Macro f1: 0.453, Micro f1: 0.492
* 4th run: Macro f1: 0.482, Micro f1: 0.492
* 5th run: Macro f1: 0.472, Micro f1: 0.482

6. BERT:
* 1st run: Macro f1: 0.164, Micro f1: 0.274
* 2nd run: Macro f1: 0.27, Micro f1: 0.294
* 3rd run: Macro f1: 0.262, Micro f1: 0.299
* 4th run: Macro f1: 0.276, Micro f1: 0.33
* 5th run: Macro f1: 0.23, Micro f1: 0.289