{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Import all necessary libraries and install everything you need for training:","metadata":{}},{"cell_type":"code","source":"# install pytorch\n!conda install --yes pytorch>=1.6 cudatoolkit=11.0 -c pytorch","metadata":{"execution":{"iopub.status.busy":"2022-01-04T08:20:02.093314Z","iopub.execute_input":"2022-01-04T08:20:02.094053Z","iopub.status.idle":"2022-01-04T08:21:36.585988Z","shell.execute_reply.started":"2022-01-04T08:20:02.093959Z","shell.execute_reply":"2022-01-04T08:21:36.585099Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# install simpletransformers\n!pip install -q transformers\n!pip install --upgrade transformers\n!pip install -q simpletransformers\n\n# check installed version\n!pip freeze | grep simpletransformers","metadata":{"execution":{"iopub.status.busy":"2022-01-04T08:21:36.588478Z","iopub.execute_input":"2022-01-04T08:21:36.588972Z","iopub.status.idle":"2022-01-04T08:22:12.733033Z","shell.execute_reply.started":"2022-01-04T08:21:36.588930Z","shell.execute_reply":"2022-01-04T08:22:12.732252Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# install stable torch\n!pip uninstall -q torch -y\n!pip install -q torch==1.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html","metadata":{"execution":{"iopub.status.busy":"2022-01-04T08:22:12.734723Z","iopub.execute_input":"2022-01-04T08:22:12.735070Z","iopub.status.idle":"2022-01-04T08:23:29.378741Z","shell.execute_reply.started":"2022-01-04T08:22:12.735027Z","shell.execute_reply":"2022-01-04T08:23:29.377907Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# install the libraries necessary for data wrangling, prediction and result analysis\nfrom sklearn.metrics import f1_score, ConfusionMatrixDisplay, confusion_matrix, accuracy_score\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-01-04T08:23:29.385159Z","iopub.execute_input":"2022-01-04T08:23:29.387399Z","iopub.status.idle":"2022-01-04T08:23:30.301991Z","shell.execute_reply.started":"2022-01-04T08:23:29.387357Z","shell.execute_reply":"2022-01-04T08:23:30.301291Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Import the data","metadata":{}},{"cell_type":"code","source":"# Import the data, prepared for the experiments\ntrain_df = pd.read_csv(\"/kaggle/input/gincodataframededuptraindevtest/GINCO_dataframe_dedup_train_dev.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/gincodataframededuptraindevtest/GINCO_dataframe_dedup_test.csv\")\n\nprint(\"Train shape: {}, Test shape: {}.\".format(train_df.shape, test_df.shape))","metadata":{"execution":{"iopub.status.busy":"2022-01-04T13:19:43.028483Z","iopub.execute_input":"2022-01-04T13:19:43.028935Z","iopub.status.idle":"2022-01-04T13:19:43.083159Z","shell.execute_reply.started":"2022-01-04T13:19:43.028891Z","shell.execute_reply":"2022-01-04T13:19:43.081720Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# Create a list of labels\nLABELS = train_df.labels.unique().tolist()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T13:19:43.084910Z","iopub.execute_input":"2022-01-04T13:19:43.085345Z","iopub.status.idle":"2022-01-04T13:19:43.090638Z","shell.execute_reply.started":"2022-01-04T13:19:43.085307Z","shell.execute_reply":"2022-01-04T13:19:43.089664Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# Drop the instances with no text\ntrain_df = train_df.dropna()\ntest_df = test_df.dropna()\nprint(\"Train shape: {}, Test shape: {}.\".format(train_df.shape, test_df.shape))","metadata":{"execution":{"iopub.status.busy":"2022-01-04T13:19:43.092262Z","iopub.execute_input":"2022-01-04T13:19:43.092866Z","iopub.status.idle":"2022-01-04T13:19:43.104659Z","shell.execute_reply.started":"2022-01-04T13:19:43.092805Z","shell.execute_reply":"2022-01-04T13:19:43.103694Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"## Transformers","metadata":{}},{"cell_type":"markdown","source":"Let's start with arguments which are the same for all the models.","metadata":{}},{"cell_type":"code","source":"# define hyperparameters\nmodel_args ={\"overwrite_output_dir\": True,\n             \"num_train_epochs\": 90,\n             \"labels_list\": LABELS,\n             \"learning_rate\": 1e-5,\n             \"train_batch_size\": 32,\n             \"no_cache\": True,\n             \"no_save\": True,\n             \"max_seq_length\": 300,\n             \"save_steps\": -1,\n             }","metadata":{"execution":{"iopub.status.busy":"2022-01-04T13:19:43.106940Z","iopub.execute_input":"2022-01-04T13:19:43.107405Z","iopub.status.idle":"2022-01-04T13:19:43.116301Z","shell.execute_reply.started":"2022-01-04T13:19:43.107367Z","shell.execute_reply":"2022-01-04T13:19:43.112044Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"import gc\nimport torch\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T13:19:43.117774Z","iopub.execute_input":"2022-01-04T13:19:43.118078Z","iopub.status.idle":"2022-01-04T13:19:43.416091Z","shell.execute_reply.started":"2022-01-04T13:19:43.118037Z","shell.execute_reply":"2022-01-04T13:19:43.415256Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"### SloBERTa\nSlovene model\nhttps://huggingface.co/EMBEDDIA/sloberta","metadata":{}},{"cell_type":"markdown","source":"from simpletransformers.classification import ClassificationModel\n\nsloberta_model = ClassificationModel(\n    \"camembert\", \"EMBEDDIA/sloberta\",\n    use_cuda = True,\n    num_labels = 21,\n    args = model_args)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T10:13:47.411450Z","iopub.execute_input":"2022-01-04T10:13:47.411733Z","iopub.status.idle":"2022-01-04T10:13:50.402787Z","shell.execute_reply.started":"2022-01-04T10:13:47.411700Z","shell.execute_reply":"2022-01-04T10:13:50.401976Z"}}},{"cell_type":"markdown","source":"### CroSloEngual BERT\nSlovene-Croatian-English model\nhttps://huggingface.co/EMBEDDIA/crosloengual-bert","metadata":{}},{"cell_type":"markdown","source":"from simpletransformers.classification import ClassificationModel\n\ncrosloengualbert_model = ClassificationModel(\n        \"bert\", \"EMBEDDIA/crosloengual-bert\",\n        num_labels=21,\n        use_cuda=True,\n        args=model_args\n    )","metadata":{"execution":{"iopub.status.busy":"2022-01-04T13:19:43.418082Z","iopub.execute_input":"2022-01-04T13:19:43.418402Z","iopub.status.idle":"2022-01-04T13:19:47.309707Z","shell.execute_reply.started":"2022-01-04T13:19:43.418340Z","shell.execute_reply":"2022-01-04T13:19:47.308901Z"}}},{"cell_type":"markdown","source":"### Base-sized XLM-RoBERTa\n\nMultilingual model\nhttps://huggingface.co/xlm-roberta-base","metadata":{}},{"cell_type":"code","source":"from simpletransformers.classification import ClassificationModel\n\nroberta_base_model = ClassificationModel(\n        \"xlmroberta\", \"xlm-roberta-base\",\n        num_labels=21,\n        use_cuda=True,\n        args=model_args\n    )","metadata":{"execution":{"iopub.status.busy":"2022-01-04T15:41:50.554839Z","iopub.execute_input":"2022-01-04T15:41:50.555402Z","iopub.status.idle":"2022-01-04T15:42:37.262328Z","shell.execute_reply.started":"2022-01-04T15:41:50.555360Z","shell.execute_reply":"2022-01-04T15:42:37.258730Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"### Large-sized XML-RoBERTa\nMultilingual model https://huggingface.co/xlm-roberta-large","metadata":{}},{"cell_type":"markdown","source":"from simpletransformers.classification import ClassificationModel\n\nroberta_large_model = ClassificationModel(\n        \"xlmroberta\", \"xlm-roberta-large\",\n        num_labels=21,\n        use_cuda=True,\n        args=model_args\n    )","metadata":{"execution":{"iopub.status.busy":"2022-01-03T20:07:36.13473Z","iopub.execute_input":"2022-01-03T20:07:36.136909Z","iopub.status.idle":"2022-01-03T20:07:50.811525Z","shell.execute_reply.started":"2022-01-03T20:07:36.136868Z","shell.execute_reply":"2022-01-03T20:07:50.809439Z"}}},{"cell_type":"markdown","source":"### DeBERTaV3\nMultilingual model https://huggingface.co/microsoft/mdeberta-v3-base","metadata":{}},{"cell_type":"markdown","source":"from simpletransformers.classification import ClassificationModel\n\ndebertav3_model = ClassificationModel(\n        \"debertav2\", \"microsoft/mdeberta-v3-base\",\n        num_labels=21,\n        use_cuda=True,\n        args=model_args\n    )","metadata":{"execution":{"iopub.status.busy":"2022-01-03T19:25:30.459204Z","iopub.execute_input":"2022-01-03T19:25:30.462074Z","iopub.status.idle":"2022-01-03T19:25:42.477123Z","shell.execute_reply.started":"2022-01-03T19:25:30.462035Z","shell.execute_reply":"2022-01-03T19:25:42.476282Z"}}},{"cell_type":"markdown","source":"### BERTić\nModel for related South Slavic languages https://huggingface.co/classla/bcms-bertic","metadata":{}},{"cell_type":"markdown","source":"from simpletransformers.classification import ClassificationModel\n\nbertic_model = ClassificationModel(\n        \"electra\", \"classla/bcms-bertic\",\n        num_labels=21,\n        use_cuda=True,\n        args=model_args\n    )","metadata":{"execution":{"iopub.status.busy":"2022-01-03T20:12:05.456734Z","iopub.execute_input":"2022-01-03T20:12:05.457033Z","iopub.status.idle":"2022-01-03T20:12:32.68296Z","shell.execute_reply.started":"2022-01-03T20:12:05.45699Z","shell.execute_reply":"2022-01-03T20:12:32.682204Z"}}},{"cell_type":"markdown","source":"### BERT base model (cased)\nMonolingual English model https://huggingface.co/bert-base-cased","metadata":{}},{"cell_type":"markdown","source":"from simpletransformers.classification import ClassificationModel\n\nbertbase_model = ClassificationModel(\n        \"bert\", \"bert-base-cased\",\n        num_labels=21,\n        use_cuda=True,\n        args=model_args\n    )","metadata":{"execution":{"iopub.status.busy":"2022-01-03T20:17:26.277703Z","iopub.execute_input":"2022-01-03T20:17:26.27795Z","iopub.status.idle":"2022-01-03T20:17:34.462616Z","shell.execute_reply.started":"2022-01-03T20:17:26.277915Z","shell.execute_reply":"2022-01-03T20:17:34.461738Z"}}},{"cell_type":"markdown","source":"## Training and evaluation","metadata":{}},{"cell_type":"markdown","source":"### Train","metadata":{}},{"cell_type":"code","source":"# SloBERTa\n#sloberta_model.train_model(train_df)\n\n# CroSloEngual BERT\n#crosloengualbert_model.train_model(train_df)\n\n# Base-sized XML-Roberta\nroberta_base_model.train_model(train_df)\n\n# Large-sized XML-Roberta\n#roberta_large_model.train_model(train_df)\n\n# DeBERTav3\n#debertav3_model.train_model(train_df)\n\n# BERTić\n#bertic_model.train_model(train_df)\n\n# English base-sized BERT\n#bertbase_model.train_model(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T15:42:37.264503Z","iopub.execute_input":"2022-01-04T15:42:37.265215Z","iopub.status.idle":"2022-01-04T16:20:34.402386Z","shell.execute_reply.started":"2022-01-04T15:42:37.265175Z","shell.execute_reply":"2022-01-04T16:20:34.401696Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate","metadata":{}},{"cell_type":"code","source":"def eval_model(model,plot_title=None):\n    \"\"\" Evaluates the model by calculating the micro and macro F1 score on predictions on the test data\n    and by plotting a confusion matrix which is saved automatically.\n    It takes the test data, named as \"test_df\", and labels list named \"LABELS\".\n    \n    Args: \n        model (simpletransformers.ClassificationModel): the model name.\n        plot_title (string): the title of the confusion matrix, defaults to None.\n    \n    Returns:\n        results (dict): dictionary with fields `plot_title`, `microF1`, `macroF1`, `y_true`, `y_pred`.    \n    \"\"\"\n    instance_predictions, raw_outputs = model.predict(['Danes poročamo o dogodku, ki se je zgodil 1. 1. 2020. Oseba je dejala:\"To je res nenormalen dogodek\"'])\n    print(\"Instance prediction: \", instance_predictions)\n    \n    # Get the true labels from the dataframe\n    y_true = test_df.labels\n\n    # Calculate the model's predictions\n    y_pred = model.predict(test_df.text.tolist())[0]\n    \n    macro = f1_score(y_true, y_pred, labels=LABELS, average=\"macro\")\n    micro = f1_score(y_true, y_pred, labels=LABELS,  average=\"micro\")\n    print(f\"Macro f1: {macro:0.3}, Micro f1: {micro:0.3}\")\n      \n    cm = confusion_matrix(y_true, y_pred, labels=LABELS)\n    plt.figure(figsize=(9, 9))\n    plt.imshow(cm, cmap=\"Oranges\")\n    for (i, j), z in np.ndenumerate(cm):\n        plt.text(j, i, '{:d}'.format(z), ha='center', va='center')\n    classNames = LABELS\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    tick_marks = np.arange(len(classNames))\n    plt.xticks(tick_marks, classNames, rotation=90)\n    plt.yticks(tick_marks, classNames)\n\n    metrics = f\"{micro:0.3}, {macro:0.3}\"\n    if plot_title:\n        plt.title(plot_title +\";\\n\" + metrics)\n    else:\n        plt.title(metrics)\n    plt.tight_layout()\n   \n    fig1 = plt.gcf()\n    image_title = f\"{plot_title}.png\"\n    plt.show()\n    plt.draw()\n    fig1.savefig(image_title, dpi=100)\n    \n    return {\"Run\": plot_title,\n            \"microF1\": micro,\n            \"macroF1\": macro,\n            \"y_true\": y_true.tolist(),\n            \"y_pred\": y_pred}","metadata":{"execution":{"iopub.status.busy":"2022-01-04T16:20:34.404413Z","iopub.execute_input":"2022-01-04T16:20:34.404670Z","iopub.status.idle":"2022-01-04T16:20:34.420199Z","shell.execute_reply.started":"2022-01-04T16:20:34.404634Z","shell.execute_reply":"2022-01-04T16:20:34.419455Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"Choose from the following models:\nsloberta_model(train_df), crosloengualbert_model(train_df), roberta_base_model(train_df), roberta_large_model(train_df), debertav3_model(train_df), bertic_model(train_df), bertbase_model(train_df)","metadata":{}},{"cell_type":"code","source":"rundict = eval_model(roberta_base_model,plot_title=\"XMLRobertaBase_run_1\")","metadata":{"execution":{"iopub.status.busy":"2022-01-04T16:20:34.422532Z","iopub.execute_input":"2022-01-04T16:20:34.422825Z","iopub.status.idle":"2022-01-04T16:20:41.729381Z","shell.execute_reply.started":"2022-01-04T16:20:34.422779Z","shell.execute_reply":"2022-01-04T16:20:41.728471Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"rundict[\"run\"] = 1\nrundict[\"model\"] = \"XMLRobertaBase\"\nprint(rundict)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T16:20:41.730840Z","iopub.execute_input":"2022-01-04T16:20:41.731654Z","iopub.status.idle":"2022-01-04T16:20:41.738314Z","shell.execute_reply.started":"2022-01-04T16:20:41.731611Z","shell.execute_reply":"2022-01-04T16:20:41.737475Z"},"trusted":true},"execution_count":74,"outputs":[]}]}