{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Comparing Transformers based on the size"]},{"cell_type":"markdown","metadata":{},"source":["In this notebook, I'll compare the base- and large-sized XML-RoBERTa. The setup is the same to the setup for the first experiments, the only difference is in the following hyperparameters, used due to GPU memory size constraint on the Kaggle environment (the large-sized XML-Roberta raises errors if the max_seq_length or the batch size are too large.)\n","\n","* max_seq_length = 128 (default)\n","* smaller size of batches - 21"]},{"cell_type":"markdown","metadata":{},"source":["Import all necessary libraries and install everything you need for training:"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T08:20:02.094053Z","iopub.status.busy":"2022-01-04T08:20:02.093314Z","iopub.status.idle":"2022-01-04T08:21:36.585988Z","shell.execute_reply":"2022-01-04T08:21:36.585099Z","shell.execute_reply.started":"2022-01-04T08:20:02.093959Z"},"trusted":true},"outputs":[],"source":["# install pytorch\n","!conda install --yes pytorch>=1.6 cudatoolkit=11.0 -c pytorch"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T08:21:36.588972Z","iopub.status.busy":"2022-01-04T08:21:36.588478Z","iopub.status.idle":"2022-01-04T08:22:12.733033Z","shell.execute_reply":"2022-01-04T08:22:12.732252Z","shell.execute_reply.started":"2022-01-04T08:21:36.588930Z"},"trusted":true},"outputs":[],"source":["# install simpletransformers\n","!pip install -q transformers\n","!pip install --upgrade transformers\n","!pip install -q simpletransformers\n","\n","# check installed version\n","!pip freeze | grep simpletransformers"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T08:22:12.735070Z","iopub.status.busy":"2022-01-04T08:22:12.734723Z","iopub.status.idle":"2022-01-04T08:23:29.378741Z","shell.execute_reply":"2022-01-04T08:23:29.377907Z","shell.execute_reply.started":"2022-01-04T08:22:12.735027Z"},"trusted":true},"outputs":[],"source":["# install stable torch\n","!pip uninstall -q torch -y\n","!pip install -q torch==1.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T08:23:29.387399Z","iopub.status.busy":"2022-01-04T08:23:29.385159Z","iopub.status.idle":"2022-01-04T08:23:30.301991Z","shell.execute_reply":"2022-01-04T08:23:30.301291Z","shell.execute_reply.started":"2022-01-04T08:23:29.387357Z"},"trusted":true},"outputs":[],"source":["# install the libraries necessary for data wrangling, prediction and result analysis\n","from sklearn.metrics import f1_score, confusion_matrix\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{},"source":["### Import the data"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T13:19:43.028935Z","iopub.status.busy":"2022-01-04T13:19:43.028483Z","iopub.status.idle":"2022-01-04T13:19:43.083159Z","shell.execute_reply":"2022-01-04T13:19:43.081720Z","shell.execute_reply.started":"2022-01-04T13:19:43.028891Z"},"trusted":true},"outputs":[],"source":["# Import the data, prepared for the experiments\n","train_df = pd.read_csv(\"/kaggle/input/gincodataframededuptraindevtest/GINCO_dataframe_dedup_train_dev.csv\")\n","test_df = pd.read_csv(\"/kaggle/input/gincodataframededuptraindevtest/GINCO_dataframe_dedup_test.csv\")\n","\n","print(\"Train shape: {}, Test shape: {}.\".format(train_df.shape, test_df.shape))"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T13:19:43.085345Z","iopub.status.busy":"2022-01-04T13:19:43.084910Z","iopub.status.idle":"2022-01-04T13:19:43.090638Z","shell.execute_reply":"2022-01-04T13:19:43.089664Z","shell.execute_reply.started":"2022-01-04T13:19:43.085307Z"},"trusted":true},"outputs":[],"source":["# Create a list of labels\n","LABELS = train_df.labels.unique().tolist()"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T13:19:43.092866Z","iopub.status.busy":"2022-01-04T13:19:43.092262Z","iopub.status.idle":"2022-01-04T13:19:43.104659Z","shell.execute_reply":"2022-01-04T13:19:43.103694Z","shell.execute_reply.started":"2022-01-04T13:19:43.092805Z"},"trusted":true},"outputs":[],"source":["# Drop the instances with no text\n","train_df = train_df.dropna()\n","test_df = test_df.dropna()\n","print(\"Train shape: {}, Test shape: {}.\".format(train_df.shape, test_df.shape))"]},{"cell_type":"markdown","metadata":{},"source":["## Transformers"]},{"cell_type":"markdown","metadata":{},"source":["Let's start with arguments which are the same for all the models."]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T13:19:43.107405Z","iopub.status.busy":"2022-01-04T13:19:43.106940Z","iopub.status.idle":"2022-01-04T13:19:43.116301Z","shell.execute_reply":"2022-01-04T13:19:43.112044Z","shell.execute_reply.started":"2022-01-04T13:19:43.107367Z"},"trusted":true},"outputs":[],"source":["# define hyperparameters\n","model_args ={\"overwrite_output_dir\": True,\n","             \"num_train_epochs\": 90,\n","             \"labels_list\": LABELS,\n","             \"learning_rate\": 1e-5,\n","             \"train_batch_size\": 21,\n","             \"no_cache\": True,\n","             \"no_save\": True,\n","             \"max_seq_length\": 128,\n","             \"save_steps\": -1,\n","             }"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T13:19:43.118078Z","iopub.status.busy":"2022-01-04T13:19:43.117774Z","iopub.status.idle":"2022-01-04T13:19:43.416091Z","shell.execute_reply":"2022-01-04T13:19:43.415256Z","shell.execute_reply.started":"2022-01-04T13:19:43.118037Z"},"trusted":true},"outputs":[],"source":["import gc\n","import torch\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{},"source":["### Base-sized XLM-RoBERTa\n","\n","Multilingual model\n","https://huggingface.co/xlm-roberta-base"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T15:41:50.555402Z","iopub.status.busy":"2022-01-04T15:41:50.554839Z","iopub.status.idle":"2022-01-04T15:42:37.262328Z","shell.execute_reply":"2022-01-04T15:42:37.258730Z","shell.execute_reply.started":"2022-01-04T15:41:50.555360Z"},"trusted":true},"outputs":[],"source":["from simpletransformers.classification import ClassificationModel\n","\n","roberta_base_model = ClassificationModel(\n","        \"xlmroberta\", \"xlm-roberta-base\",\n","        num_labels=21,\n","        use_cuda=True,\n","        args=model_args\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["### Large-sized XML-RoBERTa\n","Multilingual model https://huggingface.co/xlm-roberta-large"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-01-03T20:07:36.136909Z","iopub.status.busy":"2022-01-03T20:07:36.13473Z","iopub.status.idle":"2022-01-03T20:07:50.811525Z","shell.execute_reply":"2022-01-03T20:07:50.809439Z","shell.execute_reply.started":"2022-01-03T20:07:36.136868Z"}},"source":["from simpletransformers.classification import ClassificationModel\n","\n","roberta_large_model = ClassificationModel(\n","        \"xlmroberta\", \"xlm-roberta-large\",\n","        num_labels=21,\n","        use_cuda=True,\n","        args=model_args\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["## Training and evaluation"]},{"cell_type":"markdown","metadata":{},"source":["### Train"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T15:42:37.265215Z","iopub.status.busy":"2022-01-04T15:42:37.264503Z","iopub.status.idle":"2022-01-04T16:20:34.402386Z","shell.execute_reply":"2022-01-04T16:20:34.401696Z","shell.execute_reply.started":"2022-01-04T15:42:37.265175Z"},"trusted":true},"outputs":[],"source":["# Base-sized XML-Roberta\n","roberta_base_model.train_model(train_df)\n","\n","# Large-sized XML-Roberta\n","#roberta_large_model.train_model(train_df)"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluate"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T16:20:34.404670Z","iopub.status.busy":"2022-01-04T16:20:34.404413Z","iopub.status.idle":"2022-01-04T16:20:34.420199Z","shell.execute_reply":"2022-01-04T16:20:34.419455Z","shell.execute_reply.started":"2022-01-04T16:20:34.404634Z"},"trusted":true},"outputs":[],"source":["def eval_model(model,plot_title=None):\n","    \"\"\" Evaluates the model by calculating the micro and macro F1 score on predictions on the test data\n","    and by plotting a confusion matrix which is saved automatically.\n","    It takes the test data, named as \"test_df\", and labels list named \"LABELS\".\n","    \n","    Args: \n","        model (simpletransformers.ClassificationModel): the model name.\n","        plot_title (string): the title of the confusion matrix, defaults to None.\n","    \n","    Returns:\n","        results (dict): dictionary with fields `plot_title`, `microF1`, `macroF1`, `y_true`, `y_pred`.    \n","    \"\"\"\n","    instance_predictions, raw_outputs = model.predict(['Danes poroƒçamo o dogodku, ki se je zgodil 1. 1. 2020. Oseba je dejala:\"To je res nenormalen dogodek\"'])\n","    print(\"Instance prediction: \", instance_predictions)\n","    \n","    # Get the true labels from the dataframe\n","    y_true = test_df.labels\n","\n","    # Calculate the model's predictions\n","    y_pred = model.predict(test_df.text.tolist())[0]\n","    \n","    macro = f1_score(y_true, y_pred, labels=LABELS, average=\"macro\")\n","    micro = f1_score(y_true, y_pred, labels=LABELS,  average=\"micro\")\n","    print(f\"Macro f1: {macro:0.3}, Micro f1: {micro:0.3}\")\n","      \n","    cm = confusion_matrix(y_true, y_pred, labels=LABELS)\n","    plt.figure(figsize=(9, 9))\n","    plt.imshow(cm, cmap=\"Oranges\")\n","    for (i, j), z in np.ndenumerate(cm):\n","        plt.text(j, i, '{:d}'.format(z), ha='center', va='center')\n","    classNames = LABELS\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    tick_marks = np.arange(len(classNames))\n","    plt.xticks(tick_marks, classNames, rotation=90)\n","    plt.yticks(tick_marks, classNames)\n","\n","    metrics = f\"{micro:0.3}, {macro:0.3}\"\n","    if plot_title:\n","        plt.title(plot_title +\";\\n\" + metrics)\n","    else:\n","        plt.title(metrics)\n","    plt.tight_layout()\n","   \n","    fig1 = plt.gcf()\n","    image_title = f\"{plot_title}.png\"\n","    plt.show()\n","    plt.draw()\n","    fig1.savefig(image_title, dpi=100)\n","    \n","    return {\"Run\": plot_title,\n","            \"microF1\": micro,\n","            \"macroF1\": macro,\n","            \"y_true\": y_true.tolist(),\n","            \"y_pred\": y_pred}"]},{"cell_type":"markdown","metadata":{},"source":["Choose from the following models:\n","roberta_base_model(train_df), roberta_large_model(train_df)"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T16:20:34.422825Z","iopub.status.busy":"2022-01-04T16:20:34.422532Z","iopub.status.idle":"2022-01-04T16:20:41.729381Z","shell.execute_reply":"2022-01-04T16:20:41.728471Z","shell.execute_reply.started":"2022-01-04T16:20:34.422779Z"},"trusted":true},"outputs":[],"source":["rundict = eval_model(roberta_base_model,plot_title=\"XMLRobertaBase_run_1\")"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T16:20:41.731654Z","iopub.status.busy":"2022-01-04T16:20:41.730840Z","iopub.status.idle":"2022-01-04T16:20:41.738314Z","shell.execute_reply":"2022-01-04T16:20:41.737475Z","shell.execute_reply.started":"2022-01-04T16:20:41.731611Z"},"trusted":true},"outputs":[],"source":["rundict[\"run\"] = 1\n","rundict[\"model\"] = \"XMLRobertaBase\"\n","print(rundict)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
